{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a394463d",
   "metadata": {},
   "source": [
    "# Face Recognition Project With OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a386a50c",
   "metadata": {},
   "source": [
    "Since we know that the Haar Cascade Classifier is nothing but Viola-Jones Algorithm. Now let's download the Weiler Jones Algorithm that is Haar Cascade Classifier for face detection. Go to https://github.com/opencv/opencv/tree/master/data/haarcascades. Here you can see the bunch of Cascade Classifiers available which will actually do the specific task. There are many pre-defined Cascade Classifier that are available. What you need to do is just download it and write some code doing the object detection. For our project download haarcascade_frontalface_default.xml."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e610d82f",
   "metadata": {},
   "source": [
    "## Load Image And Cascade Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3be73d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8be389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('faces.jpg')\n",
    "\n",
    "\n",
    "cv2.imshow('face',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7391cf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('./model/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7b3f05",
   "metadata": {},
   "source": [
    "## Apply Viola-Jones Framework(Cascade Classsifier) To Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35da558c",
   "metadata": {},
   "source": [
    "Remember we can't directly directly apply the Cascade Classifier to our image. We need to convert the image into a gray scale\n",
    "and then we need to apply to the Cascade Classifier to get the bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73085666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step-1: Convert image into gray scale\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# step-2: apply gray scale image to cascasde classifier\n",
    "box,detections = face_cascade.detectMultiScale2(gray)\n",
    "# detections/number of detections basically refers to the minimum number of neighbours, means number of neighbours\n",
    "# that was detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0e1eae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[321,  84, 385, 385],\n",
       "       [697, 107, 248, 248],\n",
       "       [ 88,  75, 316, 316],\n",
       "       [894, 573,  52,  52]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e1dcbb",
   "metadata": {},
   "source": [
    "The four rows indicate that we have the four faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76cfa438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35, 37, 10,  4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d53f9f",
   "metadata": {},
   "source": [
    "This says row1 of box has 35 neighbours detected and so on...\n",
    "Let's set some threshold value for minimum neighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee2c0153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step-1: Convert image into gray scale\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# step-2: apply gray scale image to cascasde classifier\n",
    "box,detections = face_cascade.detectMultiScale2(gray, minNeighbors=8)\n",
    "# detections/number of detections basically refers to the minimum number of neighbours, means number of neighbours\n",
    "# that was detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fe4192e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[321,  84, 385, 385],\n",
       "       [ 88,  75, 316, 316],\n",
       "       [697, 107, 248, 248]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaa2709f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35, 10, 37])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6a7a9d",
   "metadata": {},
   "source": [
    "The meaning of these boxes is that 321 and 81, these two values represents the xy-position and 385 represents width of the \n",
    "box and the next 385 represents the height of the box or precisely the width of the face and height of the face."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2ab72e",
   "metadata": {},
   "source": [
    "## Draw Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24a6e79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = img.copy()\n",
    "# step-1: Convert image into gray scale\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "# step-2: apply gray scale image to cascasde classifier\n",
    "box,detections = face_cascade.detectMultiScale2(gray,minNeighbors=8)\n",
    "# step-3: drawing bounding box\n",
    "for x,y,w,h in box:\n",
    "\n",
    "    cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),1)\n",
    "\n",
    "cv2.imshow('face detection',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4311c27e",
   "metadata": {},
   "source": [
    "## Face Detection Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee69e01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detection(img):\n",
    "\n",
    "    image = img.copy()\n",
    "    # step-1: Convert image into gray scale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    # step-2: apply gray scale image to cascasde classifier\n",
    "    box,detections = face_cascade.detectMultiScale2(gray,minNeighbors=8)\n",
    "    # step-3: drawing bounding box\n",
    "    for x,y,w,h in box:\n",
    "\n",
    "        cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),1)\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eccb7db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_detect = face_detection(img)\n",
    "\n",
    "\n",
    "cv2.imshow('face detection',img_detect)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9961ef09",
   "metadata": {},
   "source": [
    "## Real Time Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d87b925",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('./model/haarcascade_frontalface_default.xml')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "        \n",
    "    img_detect = face_detection(frame)\n",
    "    \n",
    "    cv2.imshow('Real Time Face Detection',img_detect)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "        \n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
